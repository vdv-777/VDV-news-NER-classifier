{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Проект: Многоцелевая модель для NER + event-CLS\n",
        "\n",
        "Этот Jupyter-ноутбук - пошаговый шаблон для выполнения проекта по объединённой (multi-task) модели, решающей **NER (BIO, token-level)** и **CLS (document-level multihot событий/отношений)** на датасете NEREL.\n",
        "\n",
        "Внимание: вам нужно реализовать весь рабочий код - в ноутбуке предустановлены только парсеры строкового формата. Все остальные ячейки служат как инструкции / места для вашего кода.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "839b39a8",
      "metadata": {},
      "source": [
        "#### Структура ноутбука \n",
        "\n",
        "1. Подготовка окружения (пути, seed, imports)\n",
        "2. EDA - загрузка jsonl, обзор, графики, выводы \n",
        "3. Парсинг и таргеты - здесь уже есть парсеры строкового формата NEREL; нужно реализовать сбор примеров (`build_examples_from_nerel`) \n",
        "4. Токенизация, выравнивание меток, DataLoader - реализовать `tokenize_and_align_labels`, Dataset/Collator \n",
        "5. Модель (JointModel) и кастомный loss (uncertainty-weighting) - реализовать модельный класс и loss\n",
        "6. Тренировка/валидация - training loop, оптимизатор, scheduler, логирование метрик\n",
        "7. Инференс и анализ ошибок - реализовать inference pipeline и примеры\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 1. EDA\n",
        "\n",
        "Цели:\n",
        "\n",
        "- Прочитать первые 50–200 записей `train.jsonl` (путь `/data/train.jsonl`).\n",
        "- Посчитать частоты: entity types, relation/event types.\n",
        "- Построить графики: топ-15 entity types, распределение длины текстов, число сущностей на документ.\n",
        "- Написать 2–3 коротких вывода в Markdown: что можно ожидать при моделировании (редкие типы, длинные документы и т. п.).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3dd5eb2",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f66ed78",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "534824bd",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9954f1",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Парсинг и подготовка таргетов\n",
        "\n",
        "Ниже - две заранее подготовленные функции парсинга строкового формата NEREL. Их вы получаете и можете использовать сразу (не меняйте имена).\n",
        "\n",
        "Ожидаемые дополнительные функции, которые вы должны реализовать:\n",
        "\n",
        "- `build_examples_from_nerel(records: List[dict], event_list: List[str]) -> List[dict]` - для каждого документа вернуть словарь с полями: `text`, `tokens` (word-tokenization по пробелам), `token_spans` (символьные оффсеты слов), `tags` (BIO per token), `cls_vec` (multihot длиной len(event_list)).\n",
        "\n",
        "- `make_event_list(records, K=30)` - собрать топ-K типов событий/relations и вернуть список.\n",
        "\n",
        "\n",
        "\n",
        "**Правила BIO и сопоставления:**\n",
        "\n",
        "- Токенизация для BIO - простая `text.split()` (по пробелам). Офсеты токенов вычисляются на основе поиска токена в тексте (учтите повторы; используйте скользящий указатель).\n",
        "- Для каждой сущности (start, end - символьные оффсеты) пометьте токены, которые пересекаются с интервалом сущности.\n",
        "- Метки: `B-TYPE`, `I-TYPE`, `O`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# Функции парсинга строкового формата NEREL\n",
        "def parse_entity_line(line: str):\n",
        "    parts = line.split('\\t')\n",
        "    if len(parts) < 3:\n",
        "        return None\n",
        "    ent_id = parts[0].strip()\n",
        "    type_pos = parts[1].strip()\n",
        "    text = parts[2].strip() if len(parts) > 2 else ''\n",
        "    m = re.match(r'(\\S+)\\s+(\\d+)\\s+(\\d+)', type_pos)\n",
        "    if not m:\n",
        "        return None\n",
        "    ent_type = m.group(1)\n",
        "    start = int(m.group(2))\n",
        "    end = int(m.group(3))\n",
        "    return {'id': ent_id, 'type': ent_type, 'start': start, 'end': end, 'text': text}\n",
        "\n",
        "def parse_relation_line(line: str):\n",
        "    parts = line.split('\\t')\n",
        "    if len(parts) < 2:\n",
        "        return None\n",
        "    rel_id = parts[0].strip()\n",
        "    body = parts[1].strip()\n",
        "    m = re.match(r'(\\S+)\\s+Arg1:(\\S+)\\s+Arg2:(\\S+)', body)\n",
        "    if not m:\n",
        "        return None\n",
        "    rel_type = m.group(1)\n",
        "    arg1 = m.group(2); arg2 = m.group(3)\n",
        "    return {'id': rel_id, 'type': rel_type, 'arg1': arg1, 'arg2': arg2}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3664a79d",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50a1198e",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfe2ce4e",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf724f09",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 3. Токенизация и выравнивание меток\n",
        "\n",
        "Задачи:\n",
        "\n",
        "- Выбрать `AutoTokenizer(..., use_fast=True)`.\n",
        "- Реализовать `tokenize_and_align_labels(examples, tokenizer, label2id, max_length)`:\n",
        "  - Токенизировать текст (return_offsets_mapping\n",
        "  - Преобразовать word-level BIO метки в token-level метки (subword → label = -100 / ignore_index, для первых субтокенов ставится соответствующий тег `B-`/`I-`)\n",
        "  - Вернуть словарь с `input_ids`, `attention_mask`, `labels` (token-level), `cls_labels`\n",
        "\n",
        "- Собрать `torch.utils.data.Dataset` и `DataLoader`. Можно использовать `DataCollatorForTokenClassification` либо сделать кастомный collator, который возвращает батчи с `cls_labels`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e460e1b",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10c7a387",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8506db2c",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbaeb497",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 4. Модель: `JointModel` + custom loss (uncertainty weighting)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef3d84ea",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0b8a614",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d47e19b",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 5. Training / Validation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ae28e26",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e57fab86",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8db67e9",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "658a78a1",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 6. Инференс, квантизация и анализ ошибок\n",
        "\n",
        "Проведите качественный анализ на 8–10 примерах: где NER ошибается? Какие типы сущностей плохо определяются? Насколько квантизация может ускорить инференс и сильно ли она ухудшает модель?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Заключение\n",
        "\n",
        "Этот шаблон даёт вам чёткую дорожную карту и рабочие точки, где нужно реализовать код. В ноутбуке предоставлены только парсеры строкового формата - всё остальное вы пишете самостоятельно: токенизация/выравнивание меток, датасеты, модель, loss, тренировка и анализ.\n",
        "\n",
        "Удачи - приступайте к реализации прямо в ноутбуке!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
